<!DOCTYPE html>

<html>

<head>

<meta charset="utf-8" />
<meta name="generator" content="pandoc" />
<meta http-equiv="X-UA-Compatible" content="IE=EDGE" />




<title>Voraussetzungen im GLM</title>

<script src="site_libs/jquery-1.11.3/jquery.min.js"></script>
<meta name="viewport" content="width=device-width, initial-scale=1" />
<link href="site_libs/bootstrap-3.3.5/css/flatly.min.css" rel="stylesheet" />
<script src="site_libs/bootstrap-3.3.5/js/bootstrap.min.js"></script>
<script src="site_libs/bootstrap-3.3.5/shim/html5shiv.min.js"></script>
<script src="site_libs/bootstrap-3.3.5/shim/respond.min.js"></script>
<script src="site_libs/jqueryui-1.11.4/jquery-ui.min.js"></script>
<link href="site_libs/tocify-1.9.1/jquery.tocify.css" rel="stylesheet" />
<script src="site_libs/tocify-1.9.1/jquery.tocify.js"></script>
<script src="site_libs/navigation-1.1/tabsets.js"></script>
<link href="site_libs/font-awesome-5.1.0/css/all.css" rel="stylesheet" />
<link href="site_libs/font-awesome-5.1.0/css/v4-shims.css" rel="stylesheet" />
<link rel="shortcut icon" href="images/broom.ico">


<style type="text/css">code{white-space: pre;}</style>
<style type="text/css" data-origin="pandoc">
code.sourceCode > span { display: inline-block; line-height: 1.25; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode { white-space: pre; position: relative; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
code.sourceCode { white-space: pre-wrap; }
code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {  background-color: #f8f8f8; }
@media screen {
code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ef2929; } /* Alert */
code span.an { color: #8f5902; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #c4a000; } /* Attribute */
code span.bn { color: #0000cf; } /* BaseN */
code span.cf { color: #204a87; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4e9a06; } /* Char */
code span.cn { color: #000000; } /* Constant */
code span.co { color: #8f5902; font-style: italic; } /* Comment */
code span.cv { color: #8f5902; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #8f5902; font-weight: bold; font-style: italic; } /* Documentation */
code span.dt { color: #204a87; } /* DataType */
code span.dv { color: #0000cf; } /* DecVal */
code span.er { color: #a40000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #0000cf; } /* Float */
code span.fu { color: #000000; } /* Function */
code span.im { } /* Import */
code span.in { color: #8f5902; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #204a87; font-weight: bold; } /* Keyword */
code span.op { color: #ce5c00; font-weight: bold; } /* Operator */
code span.ot { color: #8f5902; } /* Other */
code span.pp { color: #8f5902; font-style: italic; } /* Preprocessor */
code span.sc { color: #000000; } /* SpecialChar */
code span.ss { color: #4e9a06; } /* SpecialString */
code span.st { color: #4e9a06; } /* String */
code span.va { color: #000000; } /* Variable */
code span.vs { color: #4e9a06; } /* VerbatimString */
code span.wa { color: #8f5902; font-weight: bold; font-style: italic; } /* Warning */

</style>
<script>
// apply pandoc div.sourceCode style to pre.sourceCode instead
(function() {
  var sheets = document.styleSheets;
  for (var i = 0; i < sheets.length; i++) {
    if (sheets[i].ownerNode.dataset["origin"] !== "pandoc") continue;
    try { var rules = sheets[i].cssRules; } catch (e) { continue; }
    for (var j = 0; j < rules.length; j++) {
      var rule = rules[j];
      // check if there is a div.sourceCode rule
      if (rule.type !== rule.STYLE_RULE || rule.selectorText !== "div.sourceCode") continue;
      var style = rule.style.cssText;
      // check if color or background-color is set
      if (rule.style.color === '' && rule.style.backgroundColor === '') continue;
      // replace div.sourceCode by a pre.sourceCode rule
      sheets[i].deleteRule(j);
      sheets[i].insertRule('pre.sourceCode{' + style + '}', j);
    }
  }
})();
</script>
<style type="text/css">
  pre:not([class]) {
    background-color: white;
  }
</style>


<style type="text/css">
h1 {
  font-size: 34px;
}
h1.title {
  font-size: 38px;
}
h2 {
  font-size: 30px;
}
h3 {
  font-size: 24px;
}
h4 {
  font-size: 18px;
}
h5 {
  font-size: 16px;
}
h6 {
  font-size: 12px;
}
.table th:not([align]) {
  text-align: left;
}
</style>




<style type = "text/css">
.main-container {
  max-width: 940px;
  margin-left: auto;
  margin-right: auto;
}
code {
  color: inherit;
  background-color: rgba(0, 0, 0, 0.04);
}
img {
  max-width:100%;
}
.tabbed-pane {
  padding-top: 12px;
}
.html-widget {
  margin-bottom: 20px;
}
button.code-folding-btn:focus {
  outline: none;
}
summary {
  display: list-item;
}
</style>


<style type="text/css">
/* padding for bootstrap navbar */
body {
  padding-top: 60px;
  padding-bottom: 40px;
}
/* offset scroll position for anchor links (for fixed navbar)  */
.section h1 {
  padding-top: 65px;
  margin-top: -65px;
}
.section h2 {
  padding-top: 65px;
  margin-top: -65px;
}
.section h3 {
  padding-top: 65px;
  margin-top: -65px;
}
.section h4 {
  padding-top: 65px;
  margin-top: -65px;
}
.section h5 {
  padding-top: 65px;
  margin-top: -65px;
}
.section h6 {
  padding-top: 65px;
  margin-top: -65px;
}
.dropdown-submenu {
  position: relative;
}
.dropdown-submenu>.dropdown-menu {
  top: 0;
  left: 100%;
  margin-top: -6px;
  margin-left: -1px;
  border-radius: 0 6px 6px 6px;
}
.dropdown-submenu:hover>.dropdown-menu {
  display: block;
}
.dropdown-submenu>a:after {
  display: block;
  content: " ";
  float: right;
  width: 0;
  height: 0;
  border-color: transparent;
  border-style: solid;
  border-width: 5px 0 5px 5px;
  border-left-color: #cccccc;
  margin-top: 5px;
  margin-right: -10px;
}
.dropdown-submenu:hover>a:after {
  border-left-color: #ffffff;
}
.dropdown-submenu.pull-left {
  float: none;
}
.dropdown-submenu.pull-left>.dropdown-menu {
  left: -100%;
  margin-left: 10px;
  border-radius: 6px 0 6px 6px;
}
</style>

<script>
// manage active state of menu based on current page
$(document).ready(function () {
  // active menu anchor
  href = window.location.pathname
  href = href.substr(href.lastIndexOf('/') + 1)
  if (href === "")
    href = "index.html";
  var menuAnchor = $('a[href="' + href + '"]');

  // mark it active
  menuAnchor.parent().addClass('active');

  // if it's got a parent navbar menu mark it active as well
  menuAnchor.closest('li.dropdown').addClass('active');
});
</script>

<!-- tabsets -->

<style type="text/css">
.tabset-dropdown > .nav-tabs {
  display: inline-table;
  max-height: 500px;
  min-height: 44px;
  overflow-y: auto;
  background: white;
  border: 1px solid #ddd;
  border-radius: 4px;
}

.tabset-dropdown > .nav-tabs > li.active:before {
  content: "";
  font-family: 'Glyphicons Halflings';
  display: inline-block;
  padding: 10px;
  border-right: 1px solid #ddd;
}

.tabset-dropdown > .nav-tabs.nav-tabs-open > li.active:before {
  content: "&#xe258;";
  border: none;
}

.tabset-dropdown > .nav-tabs.nav-tabs-open:before {
  content: "";
  font-family: 'Glyphicons Halflings';
  display: inline-block;
  padding: 10px;
  border-right: 1px solid #ddd;
}

.tabset-dropdown > .nav-tabs > li.active {
  display: block;
}

.tabset-dropdown > .nav-tabs > li > a,
.tabset-dropdown > .nav-tabs > li > a:focus,
.tabset-dropdown > .nav-tabs > li > a:hover {
  border: none;
  display: inline-block;
  border-radius: 4px;
  background-color: transparent;
}

.tabset-dropdown > .nav-tabs.nav-tabs-open > li {
  display: block;
  float: none;
}

.tabset-dropdown > .nav-tabs > li {
  display: none;
}
</style>

<!-- code folding -->



<style type="text/css">

#TOC {
  margin: 25px 0px 20px 0px;
}
@media (max-width: 768px) {
#TOC {
  position: relative;
  width: 100%;
}
}

@media print {
.toc-content {
  /* see https://github.com/w3c/csswg-drafts/issues/4434 */
  float: right;
}
}

.toc-content {
  padding-left: 30px;
  padding-right: 40px;
}

div.main-container {
  max-width: 1200px;
}

div.tocify {
  width: 20%;
  max-width: 260px;
  max-height: 85%;
}

@media (min-width: 768px) and (max-width: 991px) {
  div.tocify {
    width: 25%;
  }
}

@media (max-width: 767px) {
  div.tocify {
    width: 100%;
    max-width: none;
  }
}

.tocify ul, .tocify li {
  line-height: 20px;
}

.tocify-subheader .tocify-item {
  font-size: 0.90em;
}

.tocify .list-group-item {
  border-radius: 0px;
}


</style>



</head>

<body>


<div class="container-fluid main-container">


<!-- setup 3col/9col grid for toc_float and main content  -->
<div class="row-fluid">
<div class="col-xs-12 col-sm-4 col-md-3">
<div id="TOC" class="tocify">
</div>
</div>

<div class="toc-content col-xs-12 col-sm-8 col-md-9">




<div class="navbar navbar-default  navbar-fixed-top" role="navigation">
  <div class="container">
    <div class="navbar-header">
      <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#navbar">
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
      </button>
      <a class="navbar-brand" href="index.html">Chamber of Statistics</a>
    </div>
    <div id="navbar" class="navbar-collapse collapse">
      <ul class="nav navbar-nav">
        <li>
  <a href="index.html">
    <span class="fa fa-home"></span>
     
    Home
  </a>
</li>
<li class="dropdown">
  <a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" aria-expanded="false">
    Allgemeines
     
    <span class="caret"></span>
  </a>
  <ul class="dropdown-menu" role="menu">
    <li>
      <a href="software.html">Software</a>
    </li>
    <li>
      <a href="r-basics.html">R Basics</a>
    </li>
    <li>
      <a href="stil.html">Stil</a>
    </li>
    <li>
      <a href="pakete.html">Pakete</a>
    </li>
    <li>
      <a href="daten-import.html">Daten-Import</a>
    </li>
    <li>
      <a href="data-wrangling.html">Data Wrangling</a>
    </li>
  </ul>
</li>
<li class="dropdown">
  <a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" aria-expanded="false">
    Mittelwerte vergleichen
     
    <span class="caret"></span>
  </a>
  <ul class="dropdown-menu" role="menu">
    <li>
      <a href="mittelwerte-vergleichen.html">Überblick</a>
    </li>
    <li class="divider"></li>
    <li class="dropdown-header">t-Tests</li>
    <li>
      <a href="t-test-einstichprobe.html">Bei einer Stichprobe</a>
    </li>
    <li>
      <a href="t-test-unabhaengig.html">Bei unabhängigen Stichproben</a>
    </li>
    <li>
      <a href="t-test-abhaengig.html">Bei abhängigen Stichproben</a>
    </li>
    <li class="divider"></li>
    <li class="dropdown-header">ANOVAs</li>
    <li>
      <a href="einfaktorielle-anova.html">Einfaktorielle ANOVA</a>
    </li>
    <li>
      <a href="faktorielle-anova.html">Faktorielle ANOVA</a>
    </li>
    <li class="dropdown-header">ANCOVA</li>
    <li class="dropdown-header">Repeated Measures ANOVA</li>
    <li class="dropdown-header">Mixed ANOVA</li>
    <li>
      <a href="kontraste.html">Geplante Kontraste</a>
    </li>
    <li>
      <a href="post-hoc-tests.html">Post-hoc-Tests</a>
    </li>
    <li class="divider"></li>
  </ul>
</li>
<li>
  <a href="effektstaerken.html">Effektstärken</a>
</li>
      </ul>
      <ul class="nav navbar-nav navbar-right">
        <li class="dropdown">
  <a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" aria-expanded="false">
    <span class="fa fa-question"></span>
     
     
    <span class="caret"></span>
  </a>
  <ul class="dropdown-menu" role="menu">
    <li>
      <a href="voraussetzungen.html">Voraussetzungen im GLM</a>
    </li>
    <li>
      <a href="zentraler-grenzwertsatz.html">Zentraler Grenzwertsatz</a>
    </li>
  </ul>
</li>
<li>
  <a href="about.html">
    <span class="fa fa-info"></span>
     
  </a>
</li>
      </ul>
    </div><!--/.nav-collapse -->
  </div><!--/.container -->
</div><!--/.navbar -->

<div class="fluid-row" id="header">



<h1 class="title toc-ignore">Voraussetzungen im GLM</h1>

</div>


<p>Wenn wir von Methoden in der Psychologie, oder auch der Medizin reden, meinen wir in den meisten Fällen irgendetwas, das mit dem allgemeinen linearen Modell (<strong>G</strong>enerealized <strong>L</strong>inear <strong>M</strong>odel, kurz <strong>GLM</strong>) zu tun hat. Mit diesem Modell können wir (auch nicht-) lineare Zusammenhänge darstellen und beschreiben. Grunsätzlich nehmen wir vereinfacht an: <span class="math display">\[ y = \beta_0 + \beta_1\cdot x + \varepsilon \]</span></p>
<p>An dieser Stelle verzichten wir mal auf den Index, denn hier geht es um die generelle Idee. Wir versuchen den Wert eines Probanden auf einer abhängigen Variable (<span class="math inline">\(y\)</span>) durch eine lineare Kombination (= Addition) von Einflüssen dazustellen. Diese können dann so etwas sein, wie der <span class="math inline">\(y\)</span>-Achsen-Abschnitt (<span class="math inline">\(\beta_0\)</span>) und die Steigung einer Geraden (<span class="math inline">\(\beta_1\)</span>) in Abhängigkeit von einer unabhängigen Variable (<span class="math inline">\(x\)</span>). Natürlich ist unser Modell nie perfekt, wir können es immer nur schätzen. Und da das Modell immer eine vereinfachte Form der Wirklichkeit ist, die Wirklichkeit alos viel komplizierter ist, rechnen wir bereits damit, dass wir Fehler machen, die wir Residuen nennen (<span class="math inline">\(\varepsilon\)</span>). Dieses einfache Modell können wir dann um viel mehr Variablen erweitern und transformieren.</p>
<p>Wichtig ist allerdings, dass wir uns, egal wie kompliziert das Modell auch sein mag, immer noch im GLM bewegen. Die Qualität und Teststatistiken des Modells hängen dabei jedoch an bestimmten Voraussetzungen oder Annahmen an das Modell. Bei <strong>parametrischen</strong> Tests haben diese viel mit der Normalverteilung zu tun. Die wichtigsten Annahmen sind dabei</p>
<ul>
<li>Additivität und Linearität</li>
<li>Normalverteilung</li>
<li>Homoskedastizität</li>
<li>Unabhängigkeit</li>
</ul>
<p>Verletzungen dieser Annahmen haben Auswirkungen auf die Schätzung der <strong>Parameter</strong> an sich (die <span class="math inline">\(\beta\)</span>s), die <strong>Konfidenzintervalle</strong> dieser Parameter und die <strong>Signifikanztests</strong>. Sie können nämlich schlicht falsch sein – somit sind die Schlüsse, die wir aus ihnen ziehen, auch falsch.</p>
<div id="additivität" class="section level1">
<h1>Additivität</h1>
<p>Die Annahme der Additivität ist relativ simpel. Im GLM (s.o.) haben wir uns dafür entschieden, alle Zusammenhänge als Additionen darzustellen, somit sollten die Daten auch diese Additivität wiederspiegeln. Für simple Modelle bedeutet das: Der Zusammenhang sollte linear sein. Um diese Annahme zu prüfen, sollte man für sich immer explorative Abbildungen erstellen!</p>
<p><img src="voraussetzungen_files/figure-html/unnamed-chunk-2-1.png" width="2450" style="display: block; margin: auto;" /></p>
<p>Für den linken Datensatz mit jeweils einer kontinuierlichen unabhängigen und abhängigen Variable können wir uns ohne Probleme im GLM bewegen, der Zusammenhang sieht linear aus. Der rechte Datensatz widerum ist überhaupt nicht linear. Wenn wir hier einfach Methoden des GLM zur Auswertung nutzen, werden wir alles, was uns wichtig ist (Parameter, Konfidenzintervalle, Teststatistiken) falsch schätzen.</p>
</div>
<div id="normalverteilung" class="section level1">
<h1>Normalverteilung</h1>
<p>Mit keiner anderen Voraussetzung oder Annahme wird so viel Schindluder getrieben als mit der Annahme der Normalverteilung. <strong>Nein, die Daten müssen nicht normalverteilt sein!</strong>. Was normalverteilt sein muss, hängt von der Fragestellung ab <span class="citation">(Field, <a href="#ref-Field.2018" role="doc-biblioref">2018</a>)</span>.</p>
<p>Wollen wir unsere <strong>Parameter</strong> möglichst gut schätzen (also möglichst ohne bias), dann müssen die Residuen (= Fehler des Modells) normalverteilt sein. Interessierun uns die <strong>Konfidenzintervalle</strong> oder <strong>Signifikanztests</strong>, dann muss die <em>Stichprobenkennwerteverteilung</em> normalverteilt sein <span class="citation">(Bortz &amp; Schuster, <a href="#ref-Bortz.2010" role="doc-biblioref">2010</a>; Eid et al., <a href="#ref-Eid.2017" role="doc-biblioref">2017</a>)</span>. Mal wieder so ein Begriff, mit dem die Statistiker uns das Leben schwer machen.</p>
<p>Wir zerlegen den Begriff mal in “Stichprobenkennwert” und “Verteilung”. Ein Stichprobenkennwert ist genau das, was es meint, ein Wert, mit dem die Stichprobe beschrieben wird. Am häufigsten benutzen wir da den Mittelwert oder Median der Stichprobe. Deren Verteilung soll normalverteilt sein, was wir nach dem zentralen Grenzwertsatz bei einer hinreichend großen Gruppengröße (ca. <span class="math inline">\(n &gt; 30\)</span>) automatisch annehmen können.</p>
<p>Zur Ehrenrettung der Normalverteilungs-Tester: Wenn wir mit kleinen Stichproben (<span class="math inline">\(n &lt; 30\)</span>) arbeiten, können wir nicht davon ausgehen, dass der zentrale Grenzwertsatz greift und die Stichprobenkennwerteverteilung automatisch normalverteilt ist. Wenn unsere Daten jedoch normalverteilt sind, könnten wir vermuten, dass auch die Stichprobenkennwerteverteilung normalverteilt ist. Das überprüfen wir dann mit einem QQ-Plot.</p>
<p><img src="voraussetzungen_files/figure-html/unnamed-chunk-3-1.png" width="2450" style="display: block; margin: auto;" /></p>
<p>Normalverteilte Daten erscheinen in einem QQ-Plot als Punkte auf oder an der eingezeichneten Linie. Im linken Beispiel sieht das sehr normalverteilt aus, im rechten jedoch überhaupt nicht. Um das zu überprüfen gibt es Signifikanztests, wie den Kolmogorov–Smirnov- oder Shapiro–Wilk-Test, die die Alternativhypothese testen, dass die Verteilung der betrachteten Variable nicht normalverteilt ist. Diese Tests kann man jedoch nicht empfehlen, weil sie dieselben Schwächen haben, wie alle anderen Null-Hypothesen-Signifikanztests auch. Erstens ist der <span class="math inline">\(p\)</span>-Wert abhängig von der Stichprobengröße, das heißt, dass ich mit zunehmender Stichprobengröße eine höherer Wahrscheinlichkeit habe, ein signifikantes (in diesem Falle unerwünschtes Ergebnis) zu erzielen. Selbst super aussehende Verteilungen sind dann laut Test von der Normalverteilung signifkant verschieden. Zweitens heißt ein nicht signifikantes Ergebnis <em>nicht</em>, dass die Verteilungen gleich sind <span class="citation">(Goodman, <a href="#ref-Goodman.2008" role="doc-biblioref">2008</a>)</span>.</p>
</div>
<div id="homoskedastizität" class="section level1">
<h1>Homoskedastizität</h1>
<p>Auch bekannt als Varianzhomogenität. Hiermit ist gemeint, dass die Daten für jede Stufe der unabhängigen Variable gleichmäßig streuen. Auch das überprüft man am besten mit einer Abbildung.</p>
<p><img src="voraussetzungen_files/figure-html/unnamed-chunk-4-1.png" width="2450" style="display: block; margin: auto;" /></p>
<p>Homoskedastische Daten, also Daten mit Varianzhomogenität hast Du bereits in der linken Abbildung zur Additivität gesehen, in der die Daten gleichmäßig um die blaue Linie streuten. In diesem Fall jedoch sind die Daten richtig schön nicht varianzhomogen. Zu Beginn sind alle Daten eng um die blaue Linie versammelt, aber je größer <span class="math inline">\(x\)</span> wird, desto breiter streuen die Daten. Anders ausgedrückt könnte man auch sagen, dass die Residuen (die Fehler meiner Schätzung = der Abstand der Punkte von der blauen Linie = <span class="math inline">\(\varepsilon\)</span>) <em>abhängig</em> von meiner unabhängigen Variable sind, und das darf nicht sein!</p>
<p>Gibt es Methoden, Varianzhomogenität auch mit einem Signifikanztest zu überprüfen? Na klar, Tests gibt’s für alles, aber auch hier rate nicht nur wieder ich vom Gebrauch ab <span class="citation">(Zimmerman, <a href="#ref-Zimmerman.2004" role="doc-biblioref">2004</a>)</span>. Kurz gesagt: Varianzhomogenität ist kein Problem bei gleich großen Gruppen, problemtisch wird’s bei verschieden großen Gruppen. Tests, die Varianzhomogenität prüfen, funktionieren am besten bei gleich großen Gruppen und großen Stichproben. Im Umkehrschluss bedeutet das, dass die Tests genau dann nicht richtig funktionieren, wenn es wirklich problematisch wird, also bei ungleichen Gruppengrößen und kleinen Stichproben. In diesen Fällen kann man die Ergebnisse lieber korrigieren, als die Analyse aufgrund von vorläufigen Tests gar nicht durchzuführen.</p>
</div>
<div id="unabhängigkeit" class="section level1">
<h1>Unabhängigkeit</h1>
<p>Mit der Unabhängigkeit ist eigentlich die Unabhängigkeit der Fehler (<span class="math inline">\(\varepsilon\)</span>) gemeint. Beispielweise sollen die Fehler eines Probanden nicht mit den Fehlern eines anderen Probanden zusammenhängen. Wenn man <strong>unabhängige</strong> Stichproben zieht, ist das in der Regel immer erfüllt; betrachtet man jedoch <strong>verbundene</strong> Stichproben (klassischerweise wie in Designs mit Messwiederholung), sind die Fehler nicht mehr abhängig. Stell dir einmal eine Studie vor, in der Felix und Johanna einen Test zur Stresstoleranz in drei Wochen hintereinander ausgefüllt haben. Du möchtest nun herauskriegen, ob sich der Test-Wert der beiden im Mittel verändert hat. Die Beobachtungen sind aber nicht mehr unabhängig – im Gegenteil. Felix’ Werte sind durch Felix an sich beeinflusst und Johannas Werte von Johanna. Die Werte von Felix und Johanna sind also für sich genommen ähnlicher als die Werte untereinander, weil beide individuelle “Fehler” machen. Wie man damit umgeht, wird auf den entsprechenden Seiten erklärt.</p>
</div>
<div id="robuste_Methoden" class="section level1">
<h1>Robuste Methoden</h1>
<p>Wenn die Voraussetzungen nicht erfüllt sind, hat da, wie bereits erwähnt, drastische Konsequenzen <span class="citation">(Mair &amp; Wilcox, <a href="#ref-Mair.2020" role="doc-biblioref">2020</a>; Wilcox, <a href="#ref-Wilcox.2017" role="doc-biblioref">2017</a>)</span>. Zum Glück gibt es Rand Wilcox, der viel Zeit seiner Arbeit in <strong>robuste Methoden</strong> investiert hat <span class="citation">(Wilcox, <a href="#ref-Wilcox.2017" role="doc-biblioref">2017</a>)</span>. Das sind Methoden, die keine Annahme an die Normalverteilung oder Varianzhomogenität stellen.</p>
<p><span class="citation">Wilcox (<a href="#ref-Wilcox.2017" role="doc-biblioref">2017</a>)</span> unterscheidet grob drei robuste Methoden für die von uns oft verwendeten Schätzer (Mittelwert, Standardabweichung, etc.)</p>
<ul>
<li>Trimming</li>
<li>Winsorizing</li>
<li>M-Schätzer</li>
</ul>
<p>An dieser Stelle werfe ich deutsche und englische Begriffe durcheinander, weil es nicht immer das Gegenstück in der anderen Sprache gibt.</p>
<div id="trimming" class="section level2">
<h2>Trimming</h2>
<p>Beim Trimmen nimmt man sich die Daten, ordnet sich der Größe nach und schneidet dann “oben” und “unten” einen gewissen Prozentsatz ab, z.B. 10%. Übrig bleiben dann 80% der ursprünglichen Daten, allerdings ohne einflussreiche/extrem kleine und große Werte. An dieser Stelle wird bereits deutlich, wie gut diese Methoden beim Vorhandensein von Ausreißern sind.</p>
<p>Den getrimmten Mittelwert kann R von Haus aus berechnen, indem wir der Funktion <code>mean()</code> mit <code>trim =</code> angeben, um wie viel die Daten getrimmt werden sollen. Ein guter Start sind 20%. Der Standardfehler des getrimmten Mittelwerts berechnen wir mit <code>trimse()</code> aus dem Paket <code>WRS2</code> <span class="citation">(Mair &amp; Wilcox, <a href="#ref-Mair.2020" role="doc-biblioref">2020</a>)</span>. Trimmt man <span class="math inline">\(n\)</span> Werte um einen bestimmten Prozentsatz, bleiben nach dem Trimmen <span class="math inline">\(h\)</span> Werte (Stichprobengröße nach dem Trimmen) übrig.</p>
<div class="sourceCode" id="cb1"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1-1"><a href="#cb1-1"></a><span class="kw">library</span>(WRS2)</span>
<span id="cb1-2"><a href="#cb1-2"></a></span>
<span id="cb1-3"><a href="#cb1-3"></a><span class="co"># Zufällige Werte einer schiefen Verteilung</span></span>
<span id="cb1-4"><a href="#cb1-4"></a><span class="kw">set.seed</span>(<span class="dv">20200512</span>)</span>
<span id="cb1-5"><a href="#cb1-5"></a>gruesome_data &lt;-<span class="st"> </span><span class="kw">tibble</span>(<span class="st">&quot;x&quot;</span> =<span class="st"> </span><span class="kw">c</span>(<span class="kw">round</span>(<span class="kw">rchisq</span>(<span class="dv">80</span>, <span class="dv">10</span>)), <span class="kw">rep</span>(<span class="dv">95</span><span class="op">:</span><span class="dv">100</span>, <span class="dt">times =</span> <span class="dv">2</span>)))</span>
<span id="cb1-6"><a href="#cb1-6"></a></span>
<span id="cb1-7"><a href="#cb1-7"></a><span class="co"># Getrimmter Mittelwert</span></span>
<span id="cb1-8"><a href="#cb1-8"></a>gruesome_data <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb1-9"><a href="#cb1-9"></a><span class="st">  </span><span class="kw">summarise</span>(<span class="dt">mean =</span> <span class="kw">mean</span>(x),</span>
<span id="cb1-10"><a href="#cb1-10"></a>            <span class="dt">se =</span> <span class="kw">sd</span>(x)<span class="op">/</span><span class="kw">sqrt</span>(<span class="kw">n</span>()),</span>
<span id="cb1-11"><a href="#cb1-11"></a>            <span class="dt">trimmed_mean =</span> <span class="kw">mean</span>(x, <span class="dt">trim =</span> <span class="fl">0.2</span>),</span>
<span id="cb1-12"><a href="#cb1-12"></a>            <span class="dt">trimmed_se =</span> <span class="kw">trimse</span>(x, <span class="dt">tr =</span> <span class="fl">0.2</span>))</span></code></pre></div>
<pre><code>## # A tibble: 1 x 4
##    mean    se trimmed_mean trimmed_se
##   &lt;dbl&gt; &lt;dbl&gt;        &lt;dbl&gt;      &lt;dbl&gt;
## 1  22.0  3.10         11.5      0.717</code></pre>
<p>Im direkten Vergleich des klassischen und des robusten Verfahrens fällt auf, dass sich die Werte für Mittelwert und Standardfehler doch schon gut unterscheiden – die getrimmten Werte sind deutlich kleiner.</p>
</div>
<div id="winsorizing" class="section level2">
<h2>Winsorizing</h2>
<p>Das Winsorizing funktioniert ähnlich wie das Trimmen, aber anstatt die obersten und untersten Prozent der Daten abzuschneiden, werden diese durch den jeweils verbleibenden größten, bzw. kleinsten, Wert ersetzt. Den entsprechenden Mittelwert errechnet man mit <code>winmean()</code> und den Standardfehler mit <code>winse()</code></p>
<div class="sourceCode" id="cb3"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb3-1"><a href="#cb3-1"></a>gruesome_data <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb3-2"><a href="#cb3-2"></a><span class="st">  </span><span class="kw">summarise</span>(<span class="dt">mean =</span> <span class="kw">mean</span>(x),</span>
<span id="cb3-3"><a href="#cb3-3"></a>            <span class="dt">se =</span> <span class="kw">sd</span>(x)<span class="op">/</span><span class="kw">sqrt</span>(<span class="kw">n</span>()),</span>
<span id="cb3-4"><a href="#cb3-4"></a>            <span class="dt">winsorized_mean =</span> <span class="kw">winmean</span>(x, <span class="dt">tr =</span> <span class="fl">0.2</span>),</span>
<span id="cb3-5"><a href="#cb3-5"></a>            <span class="dt">winsorized_se =</span> <span class="kw">winse</span>(x, <span class="dt">tr =</span> <span class="fl">0.2</span>))</span></code></pre></div>
<pre><code>## # A tibble: 1 x 4
##    mean    se winsorized_mean winsorized_se
##   &lt;dbl&gt; &lt;dbl&gt;           &lt;dbl&gt;         &lt;dbl&gt;
## 1  22.0  3.10            11.9         0.712</code></pre>
</div>
<div id="m-schätzer" class="section level2">
<h2>M-Schätzer</h2>
<p>M-Schätzer arbeiten auf der Basis von Maximum-Likelihood-Schätzungen <span class="citation">(siehe Wilcox, <a href="#ref-Wilcox.2017" role="doc-biblioref">2017</a> für weitere Informationen)</span>. Den entsprechenden Mittelwert errechnet man mit <code>mest()</code> und den Standardfehler mit <code>mestse()</code>.</p>
<div class="sourceCode" id="cb5"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb5-1"><a href="#cb5-1"></a>gruesome_data <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb5-2"><a href="#cb5-2"></a><span class="st">  </span><span class="kw">summarise</span>(<span class="dt">mean =</span> <span class="kw">mean</span>(x),</span>
<span id="cb5-3"><a href="#cb5-3"></a>            <span class="dt">se =</span> <span class="kw">sd</span>(x)<span class="op">/</span><span class="kw">sqrt</span>(<span class="kw">n</span>()),</span>
<span id="cb5-4"><a href="#cb5-4"></a>            <span class="dt">m_est_mean =</span> <span class="kw">mest</span>(x),</span>
<span id="cb5-5"><a href="#cb5-5"></a>            <span class="dt">m_est_se =</span> <span class="kw">mestse</span>(x))</span></code></pre></div>
<pre><code>## # A tibble: 1 x 4
##    mean    se m_est_mean m_est_se
##   &lt;dbl&gt; &lt;dbl&gt;      &lt;dbl&gt;    &lt;dbl&gt;
## 1  22.0  3.10       11.7    0.785</code></pre>
</div>
<div id="vergleich-der-robusten-schätzer" class="section level2">
<h2>Vergleich der robusten Schätzer</h2>
<p>Betrachtet man die robusten Schätzer im Vergleich zu den empirischen Daten und der klassischen Methode, stellt man fest, dass die robusten Schätzer ein besseres Bild der Realität wiedergeben.</p>
<p><img src="voraussetzungen_files/figure-html/unnamed-chunk-8-1.png" width="2450" style="display: block; margin: auto;" /></p>
</div>
</div>
<div id="literatur" class="section level1 unnumbered">
<h1>Literatur</h1>
<div id="refs" class="references">
<div id="ref-Bortz.2010">
<p>Bortz, J., &amp; Schuster, C. (2010). <em>Statistik für Human- und Sozialwissenschaftler</em> (7., vollständig überarbeitete und erweiterte Auflage). Springer. <a href="https://doi.org/10.1007/978-3-642-12770-0">https://doi.org/10.1007/978-3-642-12770-0</a></p>
</div>
<div id="ref-Eid.2017">
<p>Eid, M., Gollwitzer, M., &amp; Schmitt, M. (2017). <em>Statistik und Forschungsmethoden: Mit Online-Materialien</em> (5., korrigierte Auflage). Beltz.</p>
</div>
<div id="ref-Field.2018">
<p>Field, A. P. (2018). <em>Discovering Statistics using IBM SPSS Statistics</em> (5th ed.). SAGE.</p>
</div>
<div id="ref-Goodman.2008">
<p>Goodman, S. (2008). A dirty dozen: twelve p-value misconceptions. <em>Seminars in Hematology</em>, <em>45</em>(3), 135–140. <a href="https://doi.org/10.1053/j.seminhematol.2008.04.003">https://doi.org/10.1053/j.seminhematol.2008.04.003</a></p>
</div>
<div id="ref-Mair.2020">
<p>Mair, P., &amp; Wilcox, R. R. (2020). Robust statistical methods in R using the WRS2 package. <em>Behavior Research Methods</em>, <em>52</em>(2), 464–488. <a href="https://doi.org/10.3758/s13428-019-01246-w">https://doi.org/10.3758/s13428-019-01246-w</a></p>
</div>
<div id="ref-Wilcox.2017">
<p>Wilcox, R. R. (2017). <em>Introduction to Robust Estimation and Hypothesis Testing</em> (4th ed.). Elsevier Academic Press.</p>
</div>
<div id="ref-Zimmerman.2004">
<p>Zimmerman, D. W. (2004). A note on preliminary tests of equality of variances. <em>The British Journal of Mathematical and Statistical Psychology</em>, <em>57</em>(Pt 1), 173–181. <a href="https://doi.org/10.1348/000711004849222">https://doi.org/10.1348/000711004849222</a></p>
</div>
</div>
</div>



</div>
</div>

</div>

<script>

// add bootstrap table styles to pandoc tables
function bootstrapStylePandocTables() {
  $('tr.header').parent('thead').parent('table').addClass('table table-condensed');
}
$(document).ready(function () {
  bootstrapStylePandocTables();
});


</script>

<!-- tabsets -->

<script>
$(document).ready(function () {
  window.buildTabsets("TOC");
});

$(document).ready(function () {
  $('.tabset-dropdown > .nav-tabs > li').click(function () {
    $(this).parent().toggleClass('nav-tabs-open')
  });
});
</script>

<!-- code folding -->

<script>
$(document).ready(function ()  {

    // move toc-ignore selectors from section div to header
    $('div.section.toc-ignore')
        .removeClass('toc-ignore')
        .children('h1,h2,h3,h4,h5').addClass('toc-ignore');

    // establish options
    var options = {
      selectors: "h1,h2,h3",
      theme: "bootstrap3",
      context: '.toc-content',
      hashGenerator: function (text) {
        return text.replace(/[.\\/?&!#<>]/g, '').replace(/\s/g, '_').toLowerCase();
      },
      ignoreSelector: ".toc-ignore",
      scrollTo: 0
    };
    options.showAndHide = true;
    options.smoothScroll = true;

    // tocify
    var toc = $("#TOC").tocify(options).data("toc-tocify");
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    script.src  = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML";
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>

</body>
</html>
