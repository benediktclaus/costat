---
title: "Effektstärken"
bibliography: references.bib
link-citations: yes
csl: https://raw.githubusercontent.com/citation-style-language/styles/master/apa.csl
editor_options: 
  chunk_output_type: console
---

```{r echo=FALSE, message=FALSE}
knitr::opts_chunk$set(fig.align = "center")
ggplot2::theme_set(ggplot2::theme_light())

library(tidyverse)
library(haven)
library(rstatix)
```

![](images/measure_r.jpg)

Nullhypothesen-Signifikanztests können uns ausschließlich zu einem probabilistischen Eindruck unserer Daten verhelfen. Wir lernen also etwas vor dem Hintergrund verschiedener Wahrscheinlichkeiten, und ob Effekte in diesem Sinne "statistisch signifikant" sind. Diese Methode wird mittlerweile im Rahmen eines regelrechten Signifikanz-Fetischismus unreflektiert -- und ihm wahrsten Sinne des Wortes -- ohne Rücksicht auf Verluste angewandt [@OpenScienceCollaboration.2015; @Cohen.1994; @Kovic.2016; @Easterbrook.1991]. Jeder möchte "signifikante" Ergebnisse berichten und publizieren, alles andere versackt in den stillen Friedhöfen der Wissenschaft. Warum das ein Problem ist, wird an anderer Stelle erläutert.

Durchforstet man die Literatur, wird schnell klar, das standardmäßig überprüft wird, ob ein Effekt statistisch signifikant ist. Ganz vereinfacht gesagt kann man so testen, "ob ein Effekt zufällig zustandegekommen ist". Jeder, der aber mehr als einen Schritt geradeaus denken kann, fragt sich doch intuitiv nach der **Größe** dieses Effekts. Genau dafür sind Effektstärken da; sie vermitteln uns einen Eindruck von der Größe eines Effekts, komplett unabhängig davon, ob dieser statistisch signifikant ist.

Nullhypothesen-Signifikanztests sind nämlich mit einem "Problem" behaftet: Bei großen Gruppengrößen werden selbst kleinste Effekte statistisch signifikant. Aber nur nur weil ein Effekt *statistisch* signifikant ist, heißt es noch lange nicht, dass er auch eine *Relevanz* hat. Über die Relevanz eines Effekts kann uns die Effektstärke Hinweise geben.

Auf dieser Seite unterscheiden wir häufig zwischen den "klassischen" und den "robusten" Verfahren. Auch bei Effektstärken gibt es robuste Verfahren, die weniger Anfällig gegenüber Ausreißern und schiefen Verteilungen sind. Deshalb werden wir diese beiden Gruppen auch wieder getrennt behandeln. Wer mehr zu klassischen Effektstärken erfahren möchte, sollte unbedingt @Cohen.1988 lesen. Des Weiteren kann man grob zwischen Effektstärken für Gruppenunterschiede und Zusammenhänge unterscheiden; auch dieser Gliederung wird gefolgt.

# Klassisch
## Gruppenunterschiede (unabhängig)
### Grundidee
Alle gleich folgenden Effektstärken für Gruppenunterschiede verfolgen dasselbe Ziel: Unterschiede zwischen Gruppen sollen interpretierbar werden. Es wird also einfach der Mittelwert der einen Gruppe minus den der anderen Gruppe gerechnet. Das ist eigentlich schon eine Effektstärke, weil wir eine Idee von der Größe des (rohen) Effekts bekommen. Nun ist es leider nicht so, dass in Studien immer dieselben Maße verwendet werden. Studien zur Depression benutzen ganz viele unterschiedliche Fragebögen, um das depressive Syndrom zu erfassen. Einige Autoren nutzen bspw. Becks Depressions-Inventar, andere ein eigenes Instrument. Ein Unterschied von 5 in der einen Studie ist also etwas anderes als ein Unterschied von 20 in der anderen. Um dennoch alle Studien miteinander vergleichen zu können, unabhängig davon, wie sie ihr Outcome erhoben haben, wird dieser Mittelwertunterschied **standardisiert** (durch einen bestimmten Wert geteilt). Man bringt ihn dadurch auf die Einheit von Standardabweichungen, und da alle Unterschiede in allen Studien so dieselbe Einheit haben, können wir sie miteinander vergleichen.

Im Prinzip unterscheiden sich die Effektstärken dann nur in ihrer Standardisierung. Die wichtigsten werden nun vorgestellt.

### Cohens $d$
Der Urvater der Effektstärken ist **Cohens $d$** [@Cohen.1988]. Cohens $d$ gibt den **standardisierten** Unterschied zwischen zwei Gruppen an. Das macht es besonders breit anwendbar, da viele Studien miteinander verglichen werden können. @Cohen[S. 20] schlägt vor, die Mittelwerte beider Gruppen durch die Standardabweichung zu teilen. Nach diesem Vorgehen wird angenommen, dass die Standardabweichungen der Gruppen gleich sind (deshalb teilt man nur durch *eine* Standardabweichung). Natürlich haben die beiden Gruppen in den seltensten Fällen identische Varianzen, weshalb die Formel für ungleiche Gruppengrößen und -varianzen um die **gepoolte Standardabweichung** erweitert wurde [@Cohen.1988, S. 67]. Die entsprechenden Formeln sind in der [Formelsammlung](formelsammlung.html).

In R können wir $d$ relativ einfach berechnen -- in SPSS hat man nur mit Mühe eine Chance. Als konkretes Beispiel nutzen wir den Datensatz, den wir bei den unabhängigen $t$-Tests genauer untersucht haben (`chivalry.sav`).

```{r}
# Daten laden
chivalry_data <- read_spss("data/chivalry.sav") %>%
  mutate(house = as_factor(house))

# Daten visualisieren
ggplot(chivalry_data, aes(x = house, y = chivalry)) + geom_boxplot()

# Cohens d berechnen
chivalry_data %>% cohens_d(chivalry ~ house)
```


### Hedges' $g$
Bereits @Hedges.1981 konnte zeigen, dass Cohens $d$ positiv verzerrt ist -- es kommen also zu große Werte raus. @Hedges.1981[S.110] entwickelte deshalb Hedges' $g$. Um für ausreichend Verwirrung zu sorgen, nannte Hedges selbst seine Effektstärke auch $d$; jedoch sollte man sie im Sinne einer einheitlichen Bezeichnung $g$ bezeichnen. (Die gleich folgende Effektstärke $g^*$ nannte er übrigens schlicht $g$.) Hedges geht bei der Berechnung von $g$ genau vor wie Cohen, indem er die Differenz der Gruppenmittelwerte bildet, diese jedoch durch eine **korrigierte Standardabweichung** teilt (die entsprechenden Formeln sind in der [Formelsammlung](formelsammlung.html)). Dabei handelt es sich somit nur um eine korrigierte Version von Cohens $d$ und wird auf gleiche Art und Weise interpretiert.

Auch Hedges' $g$ kann mit der Funktion `cohens_d()` berechnet werden, indem man das Argument `hedges.correction = TRUE` mitgibt.

```{r}
chivalry_data %>% cohens_d(chivalry ~ house, hedges.correction = TRUE)
```


### Hedges' $g^*$
Nur um die Sache komplizierter zu machen, berichten @Hedges.1985, dass auch $g$ bei kleinen Stichproben positiv verzerrt ist. Deshalb schlug @Hedges.1981[S. 111] einen Korrektur-Faktor $J$ für $g$ vor $g^* = g \cdot J$ (die entsprechenden Formeln sind in der [Formelsammlung](formelsammlung.html)).

Auch $g^*$ ist wieder keine komplett neue Effektstärke, sondern nur für eine natürlich auftretende positive Verzerrung korrigiert und lässt sich deshalb genau so interpretieren, wie die beiden vorigen Effektstärken.

Welche sollte man nun also nehmen? **Mit Hedges' $g^*$ ist man immer auf der richtigen Seite!** Ist die Stichprobengröße nämlich groß, nähern sich $d$, $g$ und $g^*$ dem selben Wert an, aber wann ist eine Stichprobe dafür ausreichend groß? Das kann man vorher nie so genau sagen und deshalb ist es immer sinnvoll, den konservativsten Wert zu nehmen, um den beobachteten Effekt nicht zu überschätzen.

### Glass' $\Delta$
Zu den bereits gängigen Effektstärken gibt es noch eine weitere, nämlich Glass' $\Delta$. Sie berechnet sich durch die Differenz der Mittelwerte, geteilt durch die Standardabweichung der Kontrollgruppe (die entsprechenden Formeln sind in der [Formelsammlung](formelsammlung.html)). Die Idee soll sein, dass die Varianz der Kontrollgruppe (oder deren Wurzel daraus, also die Standardabweichung) eher die der Population widerspiegelt, weil man mit ihr "noch nichts gemacht hat", weil sie z.B. keine Behandlung bekommen hat. Hier habe ich sie eher aus historischen Gründen aufgeführt.

## Zusammenhänge
### Pearsons $r$
Einer der bekanntesten Effektstärken von Zusammenhängen ist der (stinknormale) Korrelationskoeffizient nach Pearson $r$ (die entsprechenden Formeln sind in der [Formelsammlung](formelsammlung.html)).

# Robust
## Gruppenunterschiede (unabhängig)
### $\delta_t$
Auch für Cohens $d$ gibt es eine robuste Alternative -- dieses Mal jedoch nicht von Wilcox, sondern von @Algina.2005. Diese nannten die Effektstärke $\delta_t$ und kann mit der Funktion `akp.effect()` berechnet werden. Dabei ist zu beachten, dass diese Effektstärke Varianzhomogenität annimmt. Wenn man unterschiedliche Varianzen vorfindet, sollte man auf $\xi$ (s.u.) ausweichen.

```{r}
library(WRS2)

akp.effect(chivalry ~ house, data = chivalry_data)
```

### $\xi$
$\xi$ (gesprochen "ksi") wurde von @Wilcox.2011 vorgeschlagen und verfolgt die Grundidee einer *explanatory effect size*. Sie gibt also grob an, wie viel Varianz durch den Effekt "erklärt" wird. Besonders elegant ist $\xi$, weil die Varianzhomogenität nicht vorausgesetzt wird und mehr als zwei Gruppen miteinander verglichen werden können (wie bspw. in ANOVA-Designs). Berechnet wird sie durch:

```{r}
yuen.effect.ci(chivalry ~ house, data = chivalry_data)
```


# Literatur

```{r echo=FALSE}
remove(list = ls())
```