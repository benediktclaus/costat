---
title: "Effektstärken"
bibliography: references.bib
link-citations: yes
csl: https://raw.githubusercontent.com/citation-style-language/styles/master/apa.csl
editor_options: 
  chunk_output_type: console
---

```{r echo=FALSE, message=FALSE}
knitr::opts_chunk$set(fig.align = "center")
ggplot2::theme_set(ggplot2::theme_light())

library(tidyverse)
```

![](images/measure_r.jpg)

Nullhypothesen-Signifikanztests können uns ausschließlich zu einem probabilistischen Eindruck unserer Daten verhelfen. Wir lernen also etwas vor dem Hintergrund verschiedener Wahrscheinlichkeiten, und ob Effekte in diesem Sinne "statistisch signifikant" sind. Diese Methode wird mittlerweile im Rahmen eines regelrechten Signifikanz-Fetischismus unreflektiert -- und ihm wahrsten Sinne des Wortes -- ohne Rücksicht auf Verluste angewandt [@OpenScienceCollaboration.2015; @Cohen.1994; @Kovic.2016; @Easterbrook.1991]. Jeder möchte "signifikante" Ergebnisse berichten und publizieren, alles andere versackt in den stillen Friedhöfen der Wissenschaft. Warum das ein Problem ist, wird an anderer Stelle erläutert.

Durchforstet man die Literatur, wird schnell klar, das standardmäßig überprüft wird, ob ein Effekt statistisch signifikant ist. Ganz vereinfacht gesagt kann man so testen, "ob ein Effekt zufällig zustandegekommen ist". Jeder, der aber mehr als einen Schritt geradeaus denken kann, fragt sich doch intuitiv nach der **Größe** dieses Effekts. Genau dafür sind Effektstärken da; sie vermitteln uns einen Eindruck von der Größe eines Effekts, komplett unabhängig davon, ob dieser statistisch signifikant ist.

Nullhypothesen-Signifikanztests sind nämlich mit einem "Problem" behaftet: Bei großen Gruppengrößen werden selbst kleinste Effekte statistisch signifikant. Aber nur nur weil ein Effekt *statistisch* signifikant ist, heißt es noch lange nicht, dass er auch eine *Relevanz* hat. Über die Relevanz eines Effekts kann uns die Effektstärke Hinweise geben.

Auf dieser Seite unterscheiden wir häufig zwischen den "klassischen" und den "robusten" Verfahren. Auch bei Effektstärken gibt es robuste Verfahren, die weniger Anfällig gegenüber Ausreißern und schiefen Verteilungen sind. Deshalb werden wir diese beiden Gruppen auch wieder getrennt behandeln. Wer mehr zu klassischen Effektstärken erfahren möchte, sollte unbedingt @Cohen.1988 lesen. Des Weiteren kann man grob zwischen Effektstärken für Gruppenunterschiede und Zusammenhänge unterscheiden; auch dieser Gliederung wird gefolgt.

# Normal
## Gruppenunterschiede
### Grundidee
Alle gleich folgenden Effektstärken für Gruppenunterschiede verfolgen dasselbe Ziel: Unterschiede zwischen Gruppen sollen interpretierbar werden. Es wird also einfach der Mittelwert der einen Gruppe ($\mu_1$) minus den der anderen Gruppe gerechnet ($\mu_2$). Das ist eigentlich schon eine Effektstärke, weil wir eine Idee von der Größe des Effekts bekommen. Nun ist es leider nicht so, dass in Studien immer dieselben Maße verwendet werden. Studien zur Depression benutzen ganz viele unterschiedliche Fragebögen, um das depressive Syndrom zu erfassen. Einige Autoren nutzen bspw. Becks Depressions-Inventar, andere ein eigenes Instrument. Ein Unterschied von 5 in der einen Studie ist also etwas anderes als ein Unterschied von 20 in der anderen. Um dennoch alle Studien miteinander vergleichen zu können, unabhängig davon, wie sie ihr Outcome erhoben haben, wird dieser Mittelwertunterschied **standardisiert** (durch einen bestimmten Wert geteilt). Man bringt ihn dadurch auf die Einheit von Standardabweichungen, und da alle Unterschiede in allen Studien so dieselbe Einheit haben, können wir sie miteinander vergleichen.

Im Prinzip unterscheiden sich die Effektstärken dann nur in ihrer Standardisierung. Die wichtigsten werden nun vorgestellt.

### Cohens $d$
Der Urvater der Effektstärken ist **Cohens $d$** [@Cohen.1988]. Cohens $d$ gibt den **standardisierten** Unterschied zwischen zwei Gruppen an. Das macht es besonders breit anwendbar, da viele Studien miteinander verglichen werden können.  @Cohen.1988[S. 20] gibt uns die Formel^[im Sinne einer einheitlichen, einfachen und bekannten Notation, weiche ich an dieser Stelle von Cohens Notation ab und verwende die gängige Notation, die Studierende mehrheitlich lernen. Für die Übersichtlichkeit wird auf Indizes verzichtet.] $$d = \dfrac{\mu_1-\mu_2}{\sigma}$$ mit $\sigma$ als Standardabweichung der beiden Gruppen. Nach dieser Formel wird angenommen, dass die Standardabweichungen der Gruppen gleich sind (deshalb nur ein $\sigma$). Natürlich haben die beiden Gruppen in den seltensten Fällen identische Varianzen, weshalb die Formel für ungleiche Gruppengrößen und -varianzen erweitert wurde [@Cohen.1988 S. 67] $$\dfrac{\mu_1 - \mu_2}{s}$$ mit der **gepoolten Standardabweichung** $$s = \sqrt{\dfrac{\sum{(x_1 - \mu_1)^2} + \sum{(x_2 - \mu_2)^2}}{n_1 + n_2 -2}}$$ und $x_1$, sowie $x_2$ als individuelle Werte der Probanden in den Gruppen $1$ und $2$.

### Hedges' $g$
Bereits @Hedges.1981 konnte zeigen, dass Cohens $d$ positiv verzerrt ist -- es kommen also zu große Werte raus. @Hedges.1981[S.110] entwickelte deshalb Hedges' $g$^[Um für ausreichend Verwirrung zu sorgen, nannte Hedges selbst seine Effektstärke auch $d$; jedoch sollte man sie im Sinne einer einheitlichen Bezeichnung $g$ bezeichnen. Die gleich folgende Effektstärke $g^*$ nannte er schlicht $g$.] $$g = \dfrac{\mu_1 - \mu_2}{s_\text{corrected}}$$ mit der korrigierten Standardabweichung $$s_\text{corrected} = \sqrt{\dfrac{(n_1 - 1) s_1^2 + (n_2 - 1)s_2^2}{n_1 + n_2 -2}}$$ Dabei handelt es sich nur um eine korrigierte Version von Cohens $d$ und wird auf gleiche Art und Weise interpretiert.

### Hedges' $g^*$
Nur um die Sache komplizierter zu machen, berichten @Hedges.1985, dass auch $g$ bei kleinen Stichproben positiv verzerrt ist. Deshalb schlug @Hedges.1981[S. 111] einen Korrektur-Faktor für $g$ vor $$g^* = g \cdot J$$ mit dem Korrektur-Faktor $$J = \dfrac{\Gamma \left(\frac{\alpha}{2}\right)}{\sqrt{\frac{\alpha}{2}} \cdot \Gamma \left(\frac{\alpha - 1}{2}\right)}$$ und $$\alpha = n_1 + n_2 - 2$$ Der Korrektur-Faktor wird, weil nicht jeder so leicht die Gamma-Funktion ($\Gamma$) berechnen kann, gerne approximativ angegeben als [@Borenstein.2009 S. 27] $$ J \approx 1 - \dfrac{3}{4(n_1 + n_2 - 2) - 1} $$

Auch $g^*$ ist wieder keine komplett neue Effektstärke, sondern nur für eine natürlich auftretende positive Verzerrung korrigiert und lässt sich deshalb genau so interpretieren, wie die beiden vorigen Effektstärken.

Welche sollte man nun also nehmen? **Mit Hedges' $g^*$ ist man immer auf der richtigen Seite!**

### Glass' $\Delta$
Zu den bereits gängigen Effektstärken gibt es noch eine weitere, nämlich Glass' $\Delta$. Sie berechnet sich als $$\Delta = \dfrac{\mu_1 - \mu_2}{\sigma_\text{Kontrollgruppe}}$$ Die Idee soll sein, dass die Varianz der Kontrollgruppe (oder deren Wurzel daraus, also $\sigma$) eher die Population widerspiegelt, weil man mit ihr "noch nichts gemacht hat", weil sie z.B. keine Behandlung bekommen hat. Hier habe ich sie eher aus historischen Gründen aufgeführt.

## Zusammenhänge
### Pearsons $r$
Einer der bekanntesten Effektstärken von Zusammenhängen ist der (stinknormale) Korrelationskoeffzient nach Pearson $r$ $$r = \dfrac{1}{n-1}\sum_{i = 1}^n{\left(\frac{x_i - \bar{x}}{s_x}\right)\left(\frac{y_i - \bar{y}}{s_y}\right)}$$

# Robust

# Literatur

```{r echo=FALSE}
remove(list = ls())
```