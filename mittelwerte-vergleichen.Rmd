---
title: "Überblick"
bibliography: references.bib
link-citations: yes
csl: https://raw.githubusercontent.com/citation-style-language/styles/master/apa.csl
editor_options: 
  chunk_output_type: console
---

```{r echo=FALSE}
knitr::opts_chunk$set(fig.align = "center")
```


# $t$-Tests
Der $t$-Test, oder besser gesagt die $t$-Tests, sind eine kleine Gruppe von statistischen Signifikanztests, mit denen man Gruppenunterschiede untersuchen kann. Meistens unterscheidet man zwischen dem

* Einstichproben-$t$-Test, dem
* $t$-Test mit unabhängigen Stichproben und dem
* $t$-Test mit abhängigen (oder verbundenen) Stichproben.

Na super, drei Tests -- aber ich wollte doch nur einen Test machen! Welchen nehme ich denn jetzt?!

Den Einstichproben-$t$-Test benutzt man, wenn man eine Aussage darüber treffen will, ob sich eine Population im Mittelwert von einem bereits bekannten Wert unterscheidet. Stell Dir vor, Du hast zufällig die Größe von 80 Leuten in der Dortmunder Innenstadt gemessen, die im Schnitt 181 cm groß sind. Nun möchtest Du wissen, ob sich diese mittlere Größe von Dortmundern von beispielweise 170 cm signifikant unterscheidet. Das kannst du mit einem Einstichproben-$t$-Test überprüfen (auch wenn man diese Fragestellung "in der freien Wildbahn" eigentlich nicht findet).  
[Hier geht's zur Anleitung](t-test-einstichprobe.html).

Der $t$-Test mit unabhängigen Stichproben ist in der Regel schon etwas anwendungsnäher, denn bei diesem wird untersucht, ob sich **zwei Gruppen**  in ihrem Mittelwert unterscheiden. Beispielsweise möchtest Du untersuchen, ob sich die Kontrollgruppe am Ende einer Interventions-Studie signifikant von Deiner Interventionsgruppe unterscheidet. Im Gegensatz zum vorherigen Test, werden hier beide Mittelwerte erst einmal anhand der Probanden in den Gruppen bestimmt. Sollen also zwei Gruppen anhand einer kontinuierlichen Variable miteinander verglichen werden, ist das ein valider Ansatz. Liegen mehrere Gruppen vor, deren Mittelwerte Du anhand einer Variable auf signifikante Unterschiede vergleichen möchtest, dann solltest du über ein anderes Verfahren, wie die ANOVA (s.u.) nachdenken.  
[Hier geht's zur Anleitung](t-test-unabhaengig.html).

Der $t$-Test für abhängige, oder verbundene, Stichproben kommt zutragen, wenn die Unabhängigkeitsannahme (siehe [Voraussetzungen im GLM](voraussetzungen.html)) verletzt ist. Ein einfaches Beispiel wärst Du, der/die eine tolle Therapie für Patienten mit depressiver Störung entwickelt hat. Nun hast Du ein paar Patienten gefunden, die deine Therapie ausprobieren wollen und erhebst vor und nach der Therapie die mittlere "Depressivität". Im Anschluss daran möchtest Du jetzt herausfinden, ob sich die Werte über die Zeit signifikant verbessert haben. Pro Proband hast du einen Prä- und einen Post-Wert (= vor und nach der Therapie). Das bedeutet jedoch, dass die Unabhängigkeitsannahme verletzt ist, weil mehrere Datenpunkte von einer Person kommen. Kein Problem, bei **zwei Messungen** nutzt Du einfach den $t$-Test für verbundene Stichproben.  
[Hier geht's zur Anleitung](t-test-ahaengig.html)

Die **Daten zum fleißigen Mitrechnen** findest Du wie immer im [Git-Repository](https://github.com/benediktclaus/costat/tree/master/data).

# ANOVAs

# Literatur