---
title: "ANOVA mit Messwiederholung"
bibliography: references.bib
link-citations: yes
csl: https://raw.githubusercontent.com/citation-style-language/styles/master/apa.csl
editor_options:
  chunk_output_type: console
---

```{r echo=FALSE}
knitr::opts_chunk$set(fig.align = "center", dpi = 350)
ggplot2::theme_set(ggplot2::theme_light())


library(benelib)
```

![](images/runner_r.jpg)

Mit einer (allgemeinen) ANOVA mit Messwiederholung (*repeated measures ANOVA*) kann man mehr als zwei Gruppenmittelwerte in Abhängigkeit von kategorialen Prädiktoren vergleichen, wenn *dieselben* Probanden in mehreren Gruppen sind. Da die ANOVA ein Omnibus-Test ist, und so nur anzeigt, ob irgendwo ein signifikanter Unterschied zwischen den betrachteten Mittelwerten besteht, nutzt man entweder [Kontraste](kontraste.html) oder [Post-hoc-Tests](post-hoc-tests.html), um herauszufinden, welche Mittelwerte sich letztendlich signifikant voneinander unterscheiden. Zusätzlich kann eine [*Simple Effects Analysis*](#simple_effects) dazu genutzt werden, Unterschiede auf einzelnen Faktorstufen festzustellen.

ANOVAs mit Messwiederholung setzen auf **listenweisen Fallausschluss**, d.h., dass wenn in einer Messung eines Probanden auch nur eine Mesusng fehlt, dieser von der weiteren Analyse **komplett ausgeschlossen** wird. Generell kann man empfehlen, anstatt eine klassiche ANOVA, lieber Multilevel Linear Models zu berechnen.

# Pakete 
Alle Berechnungen und Abbildungen können wir mit unseren [Standardpaketen](pakete.html) durchführen. Wir benötigen das `tidyverse` zum Data Wrangling und zur Visualisierung der Daten. `haven` benötigen wir für den Import von SPSS-Dateien und `rstatix` für statistische Analysen. Wenn man sich den Import und das Bereinigen der Daten sparen möchte (Schritte, die man dennoch üben sollte), findet man die Daten auch im Paket `costatcompanion`.

```{r message=FALSE}
library(tidyverse)
library(haven)
library(rstatix)
library(costatcompanion)
```

```{r echo=FALSE}
library(patchwork)
```

# Beispiel 1
Viele Hobby-Läufer finden das Laufen an sich sinnvoll, aber auf Dauer ziemlich langweilig. Wer sich nicht an der Fülle der Natur erfreuen kann, oder an ein Laufband in der eigenen Wohnung gebunden ist, der lenkt sich gerne mit Musik ab. Wir vermuten, dass es nicht egal ist, welche Musik die Läufer hören, sondern dass die Musik einen Einfluss auf die Leistung der Läufer hat. Dazu haben wir ein kleines Experiment durchgeführt, um diesen Effekt zu beschreiben -- insofern es ihn gibt. Wir haben und ein paar Läufer aus den Parks des Ruhrgebiets geschnappt und uns von denen eine Liste von Musik-Titeln bewerten lassen. Für jeden Läufer konnten wir so "schlecht", "neutrale" und "Lieblings-" Titel herausfinden und in individuellen Playlists abspeichern. Nun haben wir den Läufern beim Laufen an drei aufeinanderfolgenden Tagen zufällig eine dieser drei individuellen Playlists auf die Ohren gelegt und anschließend an das Training das empfundene Durchhaltevermögen auf einer Skala von 0 -- 30 einschätzen lassen (natürlcih waren alle drei Läufe gleich lang). Höhere Werte bedeuten hierbei ein höheres, empfundenes Durchhaltevermögen.

## Klassisch
Die Daten sind in der Datei `runners.sav` oder im Paket `costatcompanion` unter demselben Namen. Der Datensatz enthält drei Variablen: Die ID der Läufer (`id`), den für den Lauf gehörten Typ von Musik (`music_type`) und das nach dem Lauf eingeschätzte Durchhaltevermögen während des Laufes (`endurance`). Wir untersuchen also eine einfaktorielle Varianzanalyse mit dem Innersubjektfaktor "Music Type" mit drei Faktorstufen ("bad", "neutral", und "favorite").

```{r}
costatcompanion::runners
```

### Voraussetzungen
Da wir uns im GLM bewegen, gelten die üblichen [Voraussetzungen](voraussetzungen.html). Zusätzlich gilt bei wiederholten Messungen jedoch noch die Voraussetzung der Sphärizität.

### EDA
Zu Beginn, schauen wir uns die Daten einmal an und lassen und deskriptive Statistiken ausgeben.

```{r}
runners %>% 
  get_summary_stats()

runners %>% 
  group_by(music_type) %>% 
  get_summary_stats()
```

```{r echo=FALSE}
runners_box <- runners %>% 
  ggplot(aes(x = music_type, y = endurance)) +
  geom_boxplot(outlier.color = NA) +
  geom_jitter(width = 0.02, alpha = 0.2) +
  stat_summary(fun = "median", geom = "line", size = 1, aes(group = 1)) +
  expand_limits(y = c(0, 30)) +
  labs(x = "Music Type", y = "Endurance")

runners_line <- runners %>% 
  ggplot(aes(x = music_type, y = endurance)) +
  stat_summary(fun.data = "mean_sd", geom = "errorbar", width = 0.1, size = 1) +
  stat_summary(fun = "mean", geom = "point") +
  stat_summary(fun = "mean", geom = "line", size = 1, aes(group = 1)) +
  expand_limits(y = c(0, 30)) +
  labs(x = "Music Type", y = "Endurance")

(runners_box | runners_line) + plot_annotation(tag_levels = "A")
```

Wir sehen einen deutlichen Trend dahingehend, dass mit "Zunahme" der Valenz der gehörten Musik, also in die Richtung von "schlechter" zu "neutraler" zur "Lieblings-" Musik, auch das eingeschätzte Durchhaltevermögen der Läufer steigt (von $M = 8.89, SD = 3.09$ auf $M = 16.2, SD = 4.00$ auf $M = 24.6, Sd = 2.68$). Wie immer gibt es mehrere Möglichkeiten, mit denen man das darstellen kann. Entweder als Boxplots mit den originalen Datenpunkten (A) oder als "klassisches" Liniendiagramm mit eingezeichneten Mittelwerten und Fehlerbalken, die $\pm$ 1 Standardabweichung anzeigen. Für ein einfaktorielles Design kann man die Boxplots bevorzugen, weil sie mit gleicher Klarheit deutlich mehr Information anzeigen können (wie z.B. Ausreißer).

Die Vaoraussetzung der Sphärizität müssen wir vorab nicht zwingend prüfen, weil uns das Paket `rstatix` unter die Arme greift. Geprüft wird diese mit Mauchlys Test. Ist dieser Test signifikant, also die Voraussetzung der Sphärizität nicht erfüllt, dann müssen die $p$-Werte korrigiert werden. Bemerkt `rtstaix` einen signifkanten Wert in Mauchlys Test, dann korrigiert es den $p$-Wert automatisch.

### Durchführung
Die eigentliche Durchführung ist, wie immer, kurz und schmerzlos.

```{r}
runners %>% 
  anova_test(dv = endurance, wid = id, within = music_type)
```

Wenn wir diesen Befehl ausführen, dann sehen wir, dass Mauchlys-Test signifikant ist -- die Variassetzung der Sphärizität ist nicht erfüllt. Eine gute Methode, um den $p$-Wert nun zu korrigieren, ist die Methode nach Greenhouse und Geisser [@Greenhouse.1959]. Um diese Korrektur^[Korrigiert werden einfach nur die Freiheitsgrade der Fehler, sie werden mit dem $\varepsilon$ der Korrektur-Methode multipliziert.], wie versprochen, automatisch zu erhalten, lassen wir uns anschließend mit `get_anova_table()`, angehängt an den bereits ausgeführten Befehl, die ANOVA-Ergebnisse ausgeben.

```{r}
runners %>% 
  anova_test(dv = endurance, wid = id, within = music_type) %>% 
  get_anova_table()
```

Das $p$ ist nun identisch mit dem `p[GG]` im vorigen Output. Empfehlen würde ich jedoch, diese Schritt nicht durchzuführen und auf `get_anova_table()` zu verzichten, da wir Informationen aus dem vorigen Schritt (`anova_test()`) beim Berichten angeben müssen. Dazu zählt insbesondere der Wert ($\varepsilon$), um den letztendlich korrigiert wurde. Standardmäßig bekommen wir zwei Korrekturen angeboten: Die bereits erwähnt nach Greenhouse und Geisser und die nach Huynh und Feldt [@Huynh.1976]. Um kenntlich zu machen, welche Korrektur man genommen hat, gibt man als Index am $\varepsilon$ am besten die Autorenkürzel an, also $\varepsilon_\text{GG}$ für Greenhouse-Geisser und $\varepsilon_\text{HF}$ für Huynh-Feldt.

Auch hier ist die ANOVA wieder nur ein **Omnibus-Test**, wir wissen also nun, dass sich die Werte zwischen unseren Gruppen irgendwo unterscheiden, aber nicht genau wo. Um das zu überprüfen, können wir [Post-hoc-Tests](post-hoc-tests.html) nutzen.

```{r}
runners %>% 
  pairwise_t_test(endurance ~ music_type, paired = TRUE, p.adjust.method = "holm")
```

Es unterscheiden sich alle Gruppen signifikant voneinander.

```{r}
runners %>% 
  cohens_d(endurance ~ music_type, hedges.correction = TRUE, paired = TRUE)
```


### Berichten
We found the type of music to have an effect on runner's perceived endurance during runs, $F(2, 85.75) = 272.11, p < .001, \varepsilon_\text{GG} = .858, \eta_G^2 = .792$. Follow up post-hoc-tests revealed statistically significant differences between all groups (all $p < .001$). The "bad" and "neutral" group differed by Hedges' $g = 1.28$, "bad" and "favorite" by $g = 3.99$, and "neutral" and "favorite" by $g = 1.73$.

## Robust
Natürlich hat Rand @Wilcox.2017 auch für ANOVAS mit Messwiederholung eine robuste Alternative entwickelt und im Paket `WRS2` [@Mair.2020] zur Verfügung gestellt. Diese kann mit dem Befehl `rmanova()` ausgeführt werden; Post-hoc-Tests mit `rmmcp()`, die Ausführung des Befehls weicht allerdings etwas von der bekannten Syntax ab.

```{r}
library(WRS2)

# Robuste ANOVA mit Messwiederholung
with(runners,
     rmanova(y = endurance, groups = music_type, block = id))

# Robuste Post-hoc-Tests
with(runners,
     rmmcp(y = endurance, groups = music_type, blocks = id))
```

Auch hier erhalten wir zuerst das Ergebnis, dass die Mittelwerte sich irgendwo signifikant unterscheiden, $F_T(1.9, 56.92) = 229.26, p < .001$. Die robusten Post-hoc-Tests zeigen uns auch hier an, dass sich alle Gruppen signifikant voneinander unterscheiden.

## Non-parametrisch
Friedman-ANOVA, allerdings nur für einfaktoriellen Designs. Wenn es mehrere Faktoren sein sollen, gibt es nur noch die robusten Alternativen (s.o.). Die Effektstärke für eine Friedman-ANOVA ist Kendalls $W$, welches sich mit `friedman_effsize()` berechnen lässt. Als Post-hoc-Test wird der Wilcoxon signed-rank test genutzt. Dabei muss darauf geachtet werden, dass die Daten in der richtigen Reihenfolge sind! D.h., dass die Daten innerhalb eines Probanden immer in derselben Reihenfolge stehen müssen (hier immer die Abfolge von "bad", "neutral" und "favorite").

```{r}
# Friedman-ANOVA
runners %>% 
  friedman_test(endurance ~ music_type | id)

# Kendalls W
runners %>% 
  friedman_effsize(endurance ~ music_type | id)

# Post-hoc-Test
runners %>% 
  wilcox_test(endurance ~ music_type, paired = TRUE, p.adjust.method = "holm")
```

Auch die Friedman-ANOVA liefert uns ein signifikantes Ergebnis, $\chi^2(2) = 96.1, p < .001, W = .942$. Auch die Post-hoc-Tests ergeben signifikante Unterschiede zwischen allen Gruppen, da in allen Fällen $p < .05$ ist.

# Aus der Praxis
Ein wirklich tolles Experiment zur Akquisition von Ängsten bei Kindern führte @Field.2006 durch. Er lud eine Reihe Kinder in sein Labor ein und erzählte ihnen Geschichten zu drei neuen Tieren (dem Quoll, dem Quokka und dem Cuscus). Dabei wurde zu einem Tier eine negative, "angsteinflößende", Geschichte erzählt, zum dem zweiten Tier eine positive und zum dritten Tier gar keine. Nun zeigte Field den Kindern drei Holzboxen, und die Kinder sollten ihre Hand auf diese Boxen legen. Der Haken an der Sache war allerdings, dass Field den Kindern erklärte, dass in diesen Holzkisten nun jeweils eines der drei vorher vorgestellten Tiere lebte. Um zu untersuchen, ob die Kinder Angst vor dem Tier mit der negativen Geschichte hatten, maß er die Zeit, die die Kinder benötigten, um ihre Hand auf die Holzkisten zu legen. Um seine Hypothese zu überprüfen, führte er eine einfaktorielle ANOVA mit Messwiederholung durch, mit dem Innersubjektfaktor "Information" mit drei Faktorstufen (negativ, positiv, keine). Die Daten finden sich in der Datei `field_2006.sav` und stammen von der [begleitenden Website](https://edge.sagepub.com/field5e) von @Field.2018. Bei Daten mit Messwiederholung erhält man meistens "unsaubere" Daten im [wide-Format](data-wrangling.html#wide_long), wie auch in diesem Fall.

```{r}
animals <- read_spss("data/field_2006.sav")

animals
```

Unsere erste Aufgabe besteht also nun darin, die Daten ins "saubere" long-Format zu überführen. Dazu nutzen wir `pivot_longer()`. Als kleines Schmankerl geben wir noch das Argument `names_prefix = "bhv"` mit, dann werden die Buchstaben "bhv" automatisch entfernt und es bleiben nur noch "neg", "pos" und "none" als Werte in der neuen Variable "information" übrig. Anschließend ändern wir unsere neue Variable "information" so, dass sie ein Faktor wird^[Wer sich den Schritt über ein anschließendes `mutate()` sparen möchte und etwas mehr Erfahrung im Tidyverse hat, der kann bereits bei `pivot_longer()` das Argument `names_ptypes = list(information = factor())` angeben; tidyr formatiert diese Variable dann direkt als Faktor.].

```{r}
animals_long <- animals %>% 
  pivot_longer(
    cols = -code,
    names_to = "information",
    names_prefix = "bhv",
    values_to = "reaction_time"
  ) %>% 
  mutate(information = as_factor(information))

animals_long
```

## Klassisch
### EDA
Zu Beginn gucken wir uns die Daten wie immer einfach mal an. Um die [Voraussetzung der Normalverteilung](voraussetzungen.html) müssen wir uns keine Sorgen machen, da wir Daten von 127 Kindern, also einer großen Stichprobe, vorliegen haben.

```{r warning=FALSE}
animals_long %>% 
  group_by(information) %>% 
  get_summary_stats(reaction_time)
```


```{r echo=FALSE}
animals_long %>% 
  ggplot(aes(x = information, y = reaction_time)) +
  geom_boxplot(outlier.color = NA) +
  geom_jitter(width = 0.02, alpha = 0.2) +
  stat_summary(fun = "median", geom = "line", size = 1, aes(group = 1)) +
  # scale_y_log10() +
  expand_limits(y = 0) +
  labs(x = "Information", y = "Reaction time")
```

Wir bekommen eine leichte Idee dahingehend, dass die untersuchten Kinder deutlich länger gebraucht haben, um ihre Hand auf die Holzkiste mit dem "gefürchteten" Tier zu legen, weil die Reaktionszeiten länger sind. Holzkisten, die vermeintlich freundliche Tiere beinhalten, oder jene, zu denen man nichts weiß, werden schneller berührt. Wie immer bei Reaktionszeiten haben wir jedoch viele, viele Ausreißer. Wir rechnen jetzt einfach mal "normal" weiter, aber behalten im Hinterkopf, dass wir definitiv das robuste Verfahren anwenden sollten^[Eine weitere Möglichkeit, vor allem bei Reaktionszeiten, ist die logarithmische Transformation der Daten, die @Field.2006 auch tatsächlich durchgeführt hat. Ob und wann das sinnvoll oder empfohlen ist, hängt immer vom Forschungsfeld ab.].

### Durchführung
Die Durchführung ist, wie immer, kurz und schmerzlos.

```{r}
animals_long %>% 
  anova_test(dv = reaction_time, wid = code, within = information)
```

Mauchlys Test auf Sphärizität ist signifikant ($W = 0.798, p < .001$), weshalb wir schleunigst eine Korrektur der Freiheitsgrade nach Greenhouse-Geisser anstreben sollten ($\varepsilon_\text{GG} = .832$). Dazu aber beim "Berichten" mehr.

Wir wissen nun, dass sich die Reaktionszeiten der Kinder *irgendwo* unterschieden, aber wo genau? Dem kommen wir mit Post-hoc-Tests auf die Schliche.

```{r}
animals_long %>% 
  pairwise_t_test(reaction_time ~ information, paired = TRUE, p.adjust.method = "holm")
```

Unser erster Eindruck bestätigt sich. Die Hand auf eine Holzkiste zu legen, in der ein "furchterregendes" Tier hockt, dauert im Vergleich zu "freundlichen" Tieren, oder jenen ohne Informationen, signifikant länger (beide $p < .001$). Der Unterschied in der Reaktionszeit zwischen Tieren mit positiver oder gar keiner Geschichte ist nicht signifikant, $p = .119$.

Effektstärken können wir uns natürlich auch wieder berechnen lassen.

```{r}
animals_long %>% 
  cohens_d(reaction_time ~ information, paired = TRUE, hedges.correction = TRUE)
```


### Berichten
We found the kind of information given to kids to have a significant influence on the observed reaction time, $F(2, 209.69) = 58.68, p < .001, \varepsilon_\text{GG} = .832, \eta_G^2 = .117$. Post-hoc-test revealed the differences between the "negative" and "positive" condition ($p < .001, g = 0.80$), as well as the "non" condition ($p < .001, g = 0.69$). The "positive" and "none" condition did not differ significantly, $p = .119, g = -0.14$.

## Robust {#beispiel_robust}
Wie wir bereits bei der explorativen Datenanalyse festgestellt haben, gibt es in diesem Datensatz eine Menge Ausreißer. Deshalb lont es sich, hier robust zu rechnen.

```{r}
# Robuste ANOVA mit Messwiederholung
with(animals_long,
     rmanova(y = reaction_time, groups = information, block = code))

# Robuste Post-hoc-Tests
with(animals_long,
     rmmcp(y = reaction_time, groups = information, block = code))
```

Auch hier erhalten wir das Ergebnis, dass sich die Werte irgendwo unterscheiden, $F_T(1.24, 94.32) = 78.15, p < .001$. Die robusten Post-hoc-Tests allerdings liefern uns ein anderes ergebnis als die klassichen Methoden. Hier unterscheiden sich auch die positive und die neutrale Bedingung voneinander, $\hat{\Psi} = -0.21, p = .014$ (zwar knapp, aber so ist Nullhypothesen-Signifikanztesten nun einmal).

## Non-paramterisch
Wer in Anbetracht der viel besser geeigneten robusten Verfahren dennoch auf non-paramtrisch setzen möchte, der führt hier die Friedman-ANOVA durch.

```{r}
# Friedman-ANOVA
animals_long %>% 
  friedman_test(reaction_time ~ information | code)

# Kendalls W
animals_long %>% 
  friedman_effsize(reaction_time ~ information | code)

# Post-hoc-Test
animals_long %>% 
  wilcox_test(reaction_time ~ information, paired = TRUE, p.adjust.method = "holm")
```

Auch mit dem non-parametrischen Verfahren erhalten wir ähnliche Ergebnisse, wie mit den robusten Verfahren. Die ANOVA an sich ist signifikant, $\chi^2(2) = 140.00, p < .001, W = .553$. Die Post-hoc-Tests zeigten signifikante Unterschiede zwischen allen Gruppen (alle $p \leq .010$).

# Beispiel 2
Auch bei ANOVAs mit Messwiederholung können natürlich mehrere Faktoren berücksichtigt werden. Unser Beispieldatensatz wurde z.B. um die Variable `motivation` erweitert, in der festgehalten wurde, ob ein Läufer zusätzlich zur gehörten Musik, an diesem Tag überhaupt motiviert war, zu laufen (daher die zwei Faktorstufen "yes" vs. "no"). Wir haben also neue Läufer rekrutiert und neue Daten gesammelt.

```{r}
costatcompanion::runners_motivation
```

```{r}
runners_motivation %>% 
  get_summary_stats()

runners_motivation %>% 
  group_by(music_type, motivation) %>% 
  get_summary_stats()
```

```{r echo=FALSE}
dodge_width <- position_dodge(width = 0.1)

runners_motivation %>% 
  ggplot(aes(music_type, endurance, color = motivation)) +
  stat_summary(fun = "mean", geom = "line", position = dodge_width, size = 1, aes(group = motivation)) +
  stat_summary(fun = "mean", geom = "point", position = dodge_width) +
  stat_summary(fun.data = "mean_sd", geom = "errorbar", width = 0.1, position = dodge_width, size = 1) +
  expand_limits(y = 0) +
  theme(legend.position = "bottom") +
  labs(x = "Music Type", y = "Endurance") +
  scale_color_personal()
```

Aus der Abbildung geht hervor, dass die Art der Musik wahrscheinlich eher einen Einfluss macht, wenn man motiviert ist. Ansonsten scheinen die Leistungen der Läufer nicht wirklich von der Art der Musik abzuhängen (blaue Linie).

```{r}
runners_motivation %>% 
  anova_test(dv = endurance, wid = id, within = c(music_type, motivation))
```

Mauchlys Test auf Sphärizität fällt für uns positiv aus (nicht signifikante Ergebnisse, da $p = .355$ und $p = .810$ und somit beide $p > .05$), weshalb wir eine "normale" ANOVA mit Messwiederholung berechnen können, ohne die Freiheitsgrade der Teststaistik im Anschluss zu korrigieren. Wir erhalten einen signifikanten Haupteffekt für den Faktor "Art der Musik", $F(2, 100) = 222.43, p < . 001, \eta_G^2 = .599$, und einen signifikanten Haupteffekt für den Faktor "Motivation beim Laufen", $F(1, 50) = 96.01, p < 001, \eta_G^2 = .288$. Viel wichtiger ist an dieser Stelle der signifikante **Interaktionseffekt**, $F(2, 100) = 168.33, p < .001, \eta_G^2 = .482$. Wenn der Interaktionseffekt signifikant ist, *können wir die Haupteffekte nicht einzeln interpretieren*. Bzw. wir können es schon (niemand hält uns davon ab), aber es macht keinen Sinn.

Bei einer ANOVA mit Messwiederholung können wir dem Interaktionseffekt wieder mit einer *Simple Effects Analysis* (siehe [faktorielle ANOVA](faktorielle-anova.html)) entgegentreten. Dabei betrachten wir den Unterschied in der gefühlten Ausdauer zwischen den Läufern pro Faktorstufe von "Art der Musik" und berechnen jeweils einfaktorielle ANOVAS. Anschließend ist es eine gute Idee, die $p$-Werte aufgrund multipler Testungen mit `adjust_pvalue()` zu korrigieren. Mit `add_significance()` können wir unsere so heiß geliebten Signifikanzsternchen ("*") ausgeben lassen.

```{r}
runners_motivation %>% 
  group_by(music_type) %>% 
  anova_test(dv = endurance, wid = id, within = motivation) %>% 
  get_anova_table() %>% 
  adjust_pvalue(method = "holm") %>% 
  add_significance()
```

Wir können aus diesem Ergebnis schließen, dass sie Die Läufer in ihrer eingeschätzten Ausdauer nicht signifikant voneinander unterscheiden, wenn sie für sie unangenehme Musik hören und nicht motiviert sind. Bei neutraler und Liebligs-Musik unterscheiden sich die Läufer jedoch signifikant voneinander, je nachdem, ob sie motiviert sind oder nicht. 

## Robust
Gibt es nur für einfaktorielle ANOVAs.

## Non-parametrisch
Gibt es nur für einfaktorielle ANOVAs.

# Literatur

```{r echo=FALSE}
remove(list = ls())
```