---
title: "$t$-Test bei unabhängigen Stichproben"
bibliography: references.bib
link-citations: yes
csl: https://raw.githubusercontent.com/citation-style-language/styles/master/apa.csl
editor_options: 
  chunk_output_type: console
---

```{r echo=FALSE}
knitr::opts_chunk$set(fig.align = "center")
ggplot2::theme_set(ggplot2::theme_light())
```

![](images/harry-potter-car_r.jpg)

Begeben wir uns in die Welt der Magie, Muggel und Zauberstäbe; tauchen wir ein in die Welt von Harry Potter [@Rowling.1997]. Auch in Hogwarts gibt es viel zu entdecken und statistisch zu entschlüsseln. Vielleicht kennst Du die vier Häuser von Hogwarts: Gryffindor, Hufflepuff, Ravenclaw und Slytherin. Jedem dieser Häuser werden verschiedene Eigenschaften nachgesagt, und jeder Schüler wird ausgehend von seinen Eigenschaften durch den sprechenden Hut einem der Häuser zugeteilt. Genau diese Eigenschaften der Schüler in den Häusern können wir uns nun einmal anschauen.


# Pakete
Alle Berechnungen und Abbildungen können wir mit unseren [Standardpaketen](pakete.html) durchführen. Wir benötigen das `tidyverse` zum Data Wrangling und zur Visualisierung der Daten. `haven` benötigen wir für den Import von SPSS-Dateien, `rstatix` für statistische Analysen und `skimr` für schnelle deskriptive Statistiken.
```{r message=FALSE}
library(tidyverse)
library(haven)
library(rstatix)
library(skimr)
```

```{r echo=FALSE}
library(patchwork)
```

# Beispiel

Es wird spannend, denn wir betrachten die Rivalität der Häuser Griffyndor und Slytherin. Dem Haus Griffyndor werden Tapferkeit, Kühnheit und Ritterlichkeit zugeschrieben -- dem Haus Slytherin, naja, eher nicht. Im Datensatz `chivalry.sav` sind die Ergebnisse eines Persönlichkeitstests zu finden, den alle in Hogwarts eingeschriebenen Bewohner dieser zwei Häuser durchführten, und der das Konstrukt "Ritterlichkeit" erfasst. Der Gesamtwert dieses Tests kann Werte zwischen 0 (keine Richtterlichkeit vorhanden) und 110 (nimmt den Kampf gegen Voldemort auf und empfängt den Tod als einen alten Freund) annehmen.
```{r}
chivalry_data <- read_spss("data/chivalry.sav")

chivalry_data <- chivalry_data %>% mutate(house = as_factor(house))

chivalry_data
```

Da wir wieder SPSS-Daten importieren, finden wir für die Variable `house` wieder den merkwürdigen Datentyp `<dbl+lbl>` vor. Hier ist R nur mehr als freundlich zu uns, indem es uns beides, die Werte-Levels und -Labels gleichzeitig anzeigt Für die Analysen benötigen wir jedoch nur die Labels als ordentliche Faktoren. Das beheben wir mit der Funktion `as_factor()` (siehe auch die Seite zum [Data Wrangling](data-wrangling.html)).

## Voraussetzungen
Es gelten die üblichen [Voraussetzungen des GLM](voraussetzungen.html).

## EDA
Auch hier betrachten wir die Daten erstmal, bevor wir irgendwelche Analysen durchführen. Beobachtet man verschiedene Gruppen, macht es Sinn, die Ausgabe der statistischen Kennwerte für jede Gruppe durchzuführen.

```{r}
chivalry_data %>% 
  group_by(house) %>% 
  skim()
```

Wir sehen einen eindeutigen Trend dahingehend, dass sich die Mitglieder Griffyndors als deutlicher ritterlicher einschätzen ($M = 92.3, SD = 6.86$) als die Mitglieder der Hauses Slytherin ($M = 48.1, SD = 8.94$). Auch in der Abbildung sehen wir diesen Unterschied deutlich. Die Boxplots (C) zeigen uns insgesamt 4 Outlier, zwei in jedem Haus. Die könnte man bei Bedarf entfernen, wir belassen es jedoch dabei und fahren fort, auch weil die Varianz der Daten in beiden Häusern ähnlich zu sein scheint. Außerdem sehen die Daten gut normalverteilt aus, was wir anhand der Kerndichteschätzungen (= "geglättetes" Histogramm in A) und dem QQ-Plot (B) erkennen können.

```{r echo=FALSE, message=FALSE}
chivalry_dens <- chivalry_data %>% 
  ggplot(aes(x = chivalry, fill = house, color = house)) +
  geom_density(alpha = 0.5) +
  labs(x = "Ritterlichkeit", y = "Dichte", fill = "Haus")

chivalry_qq <- chivalry_data %>% 
  ggplot(aes(sample = chivalry)) +
  stat_qq() +
  stat_qq_line() +
  facet_wrap(~ house, scales = "free") +
  labs(x = "Theoretisch", y = "Beobachtet")

chivalry_box <- chivalry_data %>% 
  ggplot(aes(x = house, y = chivalry)) +
  geom_boxplot() +
  expand_limits(y = 0) +
  labs(x = "Haus", y = "Ritterlichkeit")

((chivalry_dens / chivalry_qq) | chivalry_box) + plot_annotation(tag_levels = "A") & theme(legend.position = "bottom")
```

Wer auf Tests zur Überprüfung der Voraussetzungen besteht, also dem Vorgehen, von dem ich bei großen Stichproben wieder [entschieden abrate](voraussetzungen.html)), der kann diese natürlich durchführen. Wichtig ist dabei zu beachten, dass der Test der Daten "auf Normalverteilung" pro Haus, bzw. pro Gruppe, durchgeführt werden muss.

```{r}
# Shapiro-Wilk-Test
chivalry_data %>% 
  group_by(house) %>% 
  shapiro_test(chivalry)

# Levene-Test
chivalry_data %>% 
  levene_test(chivalry ~ house)
```

Auch anhand der Tests können wir in diesem Falle (alle $p > .05$) festhalten, dass die Daten nicht signifikant von einer theoretischen Normalverteilung abweichen und die Varianzen in beiden Häusern auch nicht signifikant verschieden sind. Diese Ergebnisse heißen jedoch *nicht*, dass die Daten normalverteilt und die Varianzen gleich sind.

## Durchführung
```{r}
chivalry_data %>% 
  t_test(chivalry ~ house)
```

Ja, die beiden Mitglieder der Häuser unterscheiden sich in ihrer selbst eingeschätzten Ritterlichkeit signifikant voneinander, da $p < 0.05$ ist. Wer sich die Daten in einem anderen Statistikprogramm vorgenommen und mitgerechnet hat, vielleicht sogar direkt in SPSS, der wird feststellen, dass die Werte etwas von seinen abweichen. Das liegt daran, dass R standardmäßig gar nicht den traditionellen $t$-Test (auch Students $t$-Test genannt) berechnet, sondern den **Welchs-$t$-Test**. Den kennen viele Psychologie-Studenten eigentlich als Alternative zum $t$-Test, wenn die Voraussetzungen der Normalverteilung und Varianzhomogenität verletzt sind. Auf die Prüfung dieser beiden Annahmen kann man eigentlich gänzlich verzichten und standardmäßigdirekt den Welch-Test durchführen [@Rasch.2011; @Ruxton.2006], so, wie R es auch anbietet. Wer dennoch unbedingt den "richtigen" $t$-Test haben möchte, gibt einfach ein zusätzliches Argument an und schon decken sich alle Ergebnisse.

```{r}
chivalry_data %>% 
  t_test(chivalry ~ house, var.equal = TRUE)
```

Bei Gruppenunterschieden ist nicht nur interessant, ob sich diese statistisch signifikant voneinander unterscheiden; vor allem interessiert uns die Größe des Effekts, also die Effektstärke. Auch diese lässt sich einfach berechnen. Hier sollte man immer das Argument `hedges.correction = TRUE` angeben, da Cohens $d$ von Haus aus  positiv verzerrt ist [@Hedges.1985]. Entgegen dem Namen des Befehls (`cohens_d()`) erhalten wir so nicht Cohens $d$, sondern Hedges' $g$.

```{r}
chivalry_data %>% 
  cohens_d(chivalry ~ house, hedges.correction = TRUE)
```


## Berichten
Members of the Hogwarts house "Gryffindor" yielded greater scores on a test estimating chivalry as opposed to members of house "Slytherin". The mean difference of 44.2 points was statistically significant, $t(69.2) = 24.6, p < .001$ with an effect size of Hedges' $g = 5.50$, indicating a huge effect.

# Robuste Alternativen
Folgen.

# Aus der Praxis
@Matzke.2015 ließen eine Reihe von Probanden neutrale Worte auswendig lernen. Die Autoren teilten ihre Probanden unter anderem nun in zwei Gruppen ein: die eine Gruppe ließen sie nun nach dem Lernen und vor dem Abruf (im *retention interval*) ihre Augen horizontal  bewegen, die andere Gruppe ließen sie einen Punkt fixieren. Anschließend sollten die Probanden so viele gelernte Worte wie möglich abrufen. Die Frage war nun, ob die Augenbewegung den Abruf verbessert oder verschlechtert. Die Daten aus der Original-Studie sind in der Datei `eye_movements.csv` und stammen aus der [JASP Data Library](https://jasp-stats.org/wp-content/uploads/2019/11/The_JASP_Data_Library__version_2-1.pdf) [@JASPTeam.2019].

## EDA
```{r message=FALSE}
eye_movement <- read_csv("data/eye_movements.csv") %>% 
  janitor::clean_names()

eye_movement <- eye_movement %>% 
  mutate(condition = as_factor(condition))

eye_movement
```

Wenn wir die Daten einlesen, lassen wir uns die Variablennamen direkt mit der Funktion `clean_names()` aus dem Paket `janitor` bereinigen. Nach dem Import haben wir festgestellt, dass die Variable `condition` als Zeichenfolge (`<chr>`) und nicht als Faktor eingelesen wurde. Das kann ganz leicht mit dem Befehl `as_factor()` behoben werden. Die Variable `participant_number` gibt die Nummer des Probanden an und ist uninteressant. In der Variable `condition` wird hinterlegt, welcher Proband welcher Bedingung (Horizontal vs. Fixation) zugeteilt wurde und `critical_recall` ist schließlich unsere abhängige Variable, die Anzahl der abgerufenen Worte.  Den nun bereinigten Datensatz schauen wir uns genauer an.

```{r}
eye_movement %>% 
  skim(condition)
```

Dieser ersten Übersicht können wir entnehmen, dass 25 Probanden ihre Augen horizontal bewegten und 24 einen Punkt fixierten.

```{r}
eye_movement %>% 
  group_by(condition) %>% 
  skim(critical_recall)
```

Dem ersten Eindruck nach, scheint der Abruf in der Gruppe mit horizontalen Augenbewegungen schlechter zu sein. Im Durchschnitt haben die Probanden dieser experimentellen Bedingung $M = 10.88, SD = 4.32$ Wörter abgerufen, Probanden, die einen Punkt fixierten jedoch $M = 15.29, SD = 6.38$ Worte. Den gleichen Effekt können wir ganz gut im Violin-Plot^[Der Violin-Plot ist im Prinzip nichts anderes als ein detaillierterer Boxplot. Die Breite des Körpers gibt die relative Menge an Datenpunkten wieder; ist der Körper an einer Stelle also breit, sind dort viele Datenpunkte. Die schwarze Linie kennzeichnet auch hier wieder den Median.] (C) erkennt. In beiden Bedingungen hatten wir auf jeden Fall auch richtige Brains sitzen, die maximalen abgerufenen Worte sind hier 22 und 25. Allerdings gab es auch Probanden, die nur 3 oder 4 Worte abrufen konnten. Da wir eine ziemlich kleine Stichprobe haben (in beiden Bedingungen jeweils $n < 30$), sollten wir die Daten tatsächlich auf Normalverteilung und Varianzhomogenität prüfen und uns entsprechende Abbildungen zur Beurteilung ansehen.

```{r echo=FALSE}
eye_movement_dens <- eye_movement %>% 
  ggplot(aes(x = critical_recall, fill = condition, color = condition)) +
  geom_density(alpha = 0.5) +
  labs(x = "Recall", y = "Dichte", color = "Bedingung", fill = "Bedingung")

eye_movement_qq <- eye_movement %>% 
  ggplot(aes(sample = critical_recall)) +
  stat_qq() +
  stat_qq_line() +
  facet_wrap(~ condition) +
  labs(x = "Theoretisch", y = "Beobachtet")

eye_movement_boxplot <- eye_movement %>% 
  ggplot(aes(x = condition, y = critical_recall)) +
  geom_violin(draw_quantiles = 0.5) +
  geom_jitter(width = 0.03) +
  expand_limits(y = 0) +
  labs(x = "Bedingung", y = "Recall")

((eye_movement_dens / eye_movement_qq) | eye_movement_boxplot) + plot_annotation(tag_levels = "A") & theme(legend.position = "bottom")
```

Argh! Anhand der Kerndichteschätzungen (A) und den QQ-Plots (B) können wir festhalten: Normalverteilung sieht anders aus... So ist das mit den empirischen Daten, kaum etwas erhoben, sofort nur Probleme. Die Daten der Bedingung "Horizontal" gehen noch, aber bei den Daten der Bedingung "Fixation" haben wir ernstzunehmende Probleme. Was sagen uns der Shapiro-Wilk- und der Levene-Test?

```{r}
# Shapiro-Wilk-Test
eye_movement %>% 
  group_by(condition) %>% 
  shapiro_test(critical_recall)

# Levene-Test
eye_movement %>% 
  levene_test(critical_recall ~ condition)
```

Der Shapiro-Wilk-Test bestätigt unsere Vermutung, die wir bereits aus den Abbildungen getroffen haben. Bei der "Fixation"-Bedingung wurde es eng, aber -- wie das bei Nullhypothesen-Signifikanztests halt so ist -- $p = .079$, also über $.05$, was für uns erst einmal gut ist. Der Levene-Test haut uns mit seinem Ergebnis ($p = .009$) in Kombination mit Abbildung C allerdings völlig aus den Socken. Wir können keine Varianzhomogenität mehr annehmen, also dürfen wir keinen klassischen $t$-Test rechnen! Allerdings habe ich weiter oben erwähnt, dass wir bei dieser Fragestellung auch einfach direkt den Welch-Test rechnen dürfen, der in R sowieso voreingestellt ist.

## Durchführung
Die eigentliche Analyse ist kurz und schmerzlos.

```{r}
# Welch-Test
eye_movement %>% 
  t_test(critical_recall ~ condition)

# Hedges' g
eye_movement %>% 
  cohens_d(critical_recall ~ condition, hedges.correction = TRUE)
```

Der Unterschied in der Menge der abgerufenen Worte unterscheidet sich zwischen den Experimental-Bedingungen signifikant.

## Berichten
We found that moving eyes horizontally during the retention interval reduced the amount of recalled words significantly, $t(40.3) = -2.82, g = -0.80$, with amoderate to large effect size.

# Literatur

```{r echo=FALSE}
remove(list = ls())
```